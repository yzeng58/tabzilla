\begin{tabular}{lllllllllll}
\toprule
 & \multicolumn{4}{r}{Log Loss_rank_mean} & \multicolumn{2}{r}{normalized_Log Loss__test_mean} & \multicolumn{2}{r}{normalized_Log Loss__test_std} & \multicolumn{2}{r}{train_per_1000_inst_mean_Log Loss} \\
 & min & max & mean & median & mean & median & mean & median & mean & median \\
alg_name &  &  &  &  &  &  &  &  &  &  \\
\midrule
TabPFN (default) & 1 & 21 & 7.09 & 6 & 0.01 & 0.00 & 0.03 & 0.01 & 0.00 & 0.00 \\
TabPFN & 1 & 21 & 7.09 & 6 & 0.01 & 0.00 & 0.03 & 0.01 & 0.00 & 0.00 \\
CatBoost & 1 & 32 & 9.29 & 7 & 0.02 & 0.01 & 0.02 & 0.02 & 13.89 & 1.66 \\
XGBoost & 1 & 32 & 10.17 & 7.5 & 0.02 & 0.01 & 0.02 & 0.02 & 0.73 & 0.37 \\
CatBoost (default) & 1 & 35 & 11.01 & 9 & 0.03 & 0.01 & 0.02 & 0.02 & 15.65 & 1.58 \\
Ours (default) & 1 & 40 & 11.20 & 8 & 0.03 & 0.01 & 0.02 & 0.01 & 0.00 & 0.00 \\
Ours & 1 & 40 & 11.20 & 8 & 0.03 & 0.01 & 0.02 & 0.01 & 0.00 & 0.00 \\
XGBoost (default) & 1 & 38 & 14.04 & 12 & 0.03 & 0.02 & 0.03 & 0.02 & 1.12 & 0.61 \\
SAINT & 1 & 37 & 14.17 & 12 & 0.03 & 0.02 & 0.03 & 0.02 & 202.59 & 173.23 \\
SAINT (default) & 1 & 39 & 15.34 & 14 & 0.04 & 0.02 & 0.03 & 0.02 & 136.08 & 111.65 \\
ResNet & 1 & 37 & 16.05 & 14 & 0.04 & 0.03 & 0.04 & 0.02 & 16.12 & 8.97 \\
SVM & 1 & 40 & 16.70 & 17 & 0.04 & 0.02 & 0.03 & 0.01 & 49.83 & 1.20 \\
LightGBM & 1 & 44 & 16.90 & 14.5 & 0.05 & 0.02 & 0.08 & 0.03 & 0.83 & 0.27 \\
LightGBM (default) & 1 & 39 & 16.90 & 15 & 0.05 & 0.02 & 0.04 & 0.02 & 1.18 & 0.46 \\
DANet & 1 & 43 & 17.04 & 16.5 & 0.04 & 0.03 & 0.04 & 0.03 & 71.58 & 61.35 \\
FTTransformer & 1 & 37 & 18.08 & 18.5 & 0.05 & 0.03 & 0.04 & 0.03 & 29.58 & 18.48 \\
RandomForest (default) & 2 & 39 & 18.54 & 18 & 0.08 & 0.02 & 0.02 & 0.01 & 0.49 & 0.37 \\
ResNet (default) & 1 & 42 & 18.98 & 19 & 0.07 & 0.03 & 0.05 & 0.03 & 15.23 & 8.20 \\
STG & 1 & 40 & 19.09 & 19 & 0.05 & 0.02 & 0.02 & 0.02 & 18.82 & 15.85 \\
DeepFM & 1 & 44 & 20.64 & 19 & 0.14 & 0.05 & 0.05 & 0.03 & 5.89 & 4.63 \\
RandomForest & 1 & 42 & 20.92 & 21 & 0.07 & 0.04 & 0.07 & 0.02 & 0.29 & 0.22 \\
LinearModel & 1 & 39 & 21.12 & 22 & 0.09 & 0.03 & 0.03 & 0.02 & 0.04 & 0.03 \\
SVM (default) & 1 & 42 & 21.83 & 22.5 & 0.08 & 0.03 & 0.02 & 0.01 & 1.11 & 0.37 \\
FTTransformer (default) & 1 & 39 & 22.50 & 23 & 0.12 & 0.05 & 0.06 & 0.04 & 23.86 & 14.99 \\
MLP-rtdl & 1 & 39 & 22.83 & 24 & 0.12 & 0.06 & 0.07 & 0.04 & 13.75 & 7.96 \\
TabTransformer & 1 & 39 & 23.10 & 23 & 0.09 & 0.05 & 0.04 & 0.02 & 21.02 & 12.13 \\
DeepFM (default) & 1 & 45 & 23.11 & 22 & 0.21 & 0.06 & 0.08 & 0.04 & 6.09 & 4.91 \\
NODE & 1 & 37 & 23.34 & 24.5 & 0.09 & 0.05 & 0.01 & 0.01 & 196.82 & 176.16 \\
DANet (default) & 4 & 41 & 24.26 & 24 & 0.09 & 0.05 & 0.05 & 0.03 & 44.76 & 38.53 \\
MLP & 2 & 39 & 24.59 & 25.5 & 0.12 & 0.06 & 0.05 & 0.04 & 18.29 & 10.95 \\
NODE (default) & 5 & 38 & 24.85 & 27 & 0.10 & 0.05 & 0.01 & 0.01 & 60.62 & 48.95 \\
MLP-rtdl (default) & 1 & 44 & 25.30 & 26 & 0.24 & 0.07 & 0.10 & 0.05 & 13.26 & 6.09 \\
TabNet & 1 & 45 & 25.73 & 27 & 0.17 & 0.07 & 0.15 & 0.06 & 34.62 & 29.69 \\
STG (default) & 1 & 43 & 27.19 & 28 & 0.12 & 0.05 & 0.02 & 0.01 & 16.39 & 13.62 \\
MLP (default) & 2 & 42 & 27.51 & 28.5 & 0.23 & 0.08 & 0.08 & 0.04 & 17.20 & 9.45 \\
TabNet (default) & 2 & 45 & 27.98 & 29 & 0.24 & 0.09 & 0.18 & 0.06 & 28.03 & 25.73 \\
TabTransformer (default) & 2 & 44 & 28.01 & 30 & 0.15 & 0.08 & 0.04 & 0.02 & 21.58 & 14.10 \\
NAM & 4 & 42 & 28.85 & 31 & 0.16 & 0.07 & 0.02 & 0.01 & 266.63 & 145.96 \\
VIME & 3 & 42 & 29.09 & 32 & 0.16 & 0.08 & 0.03 & 0.02 & 16.92 & 14.64 \\
KNN & 2 & 45 & 31.26 & 33 & 0.18 & 0.09 & 0.13 & 0.07 & 0.01 & 0.00 \\
DecisionTree & 1 & 44 & 31.55 & 35.5 & 0.22 & 0.15 & 0.20 & 0.14 & 0.02 & 0.01 \\
VIME (default) & 11 & 43 & 34.80 & 36.5 & 0.31 & 0.16 & 0.06 & 0.01 & 15.61 & 14.03 \\
KNN (default) & 3 & 44 & 34.82 & 37 & 0.35 & 0.19 & 0.17 & 0.12 & 0.01 & 0.00 \\
DecisionTree (default) & 1 & 45 & 35.67 & 39 & 0.49 & 0.36 & 0.29 & 0.24 & 0.02 & 0.01 \\
NAM (default) & 6 & 44 & 36.89 & 40 & 0.38 & 0.26 & 0.15 & 0.03 & 145.74 & 47.17 \\
\bottomrule
\end{tabular}
