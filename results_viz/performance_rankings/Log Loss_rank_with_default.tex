\begin{tabular}{lllllllllll}
\toprule
 & \multicolumn{4}{r}{Log Loss_rank_mean} & \multicolumn{2}{r}{normalized_Log Loss__test_mean} & \multicolumn{2}{r}{normalized_Log Loss__test_std} & \multicolumn{2}{r}{train_per_1000_inst_mean_Log Loss} \\
 & min & max & mean & median & mean & median & mean & median & mean & median \\
alg_name &  &  &  &  &  &  &  &  &  &  \\
\midrule
CatBoost & 1 & 21 & 6.21 & 4 & 0.05 & 0.02 & 0.04 & 0.02 & 28.05 & 1.24 \\
XGBoost & 1 & 32 & 6.26 & 3 & 0.03 & 0.02 & 0.04 & 0.03 & 2.14 & 0.29 \\
TabPFN (default) & 1 & 14 & 6.67 & 7 & 0.02 & 0.02 & 0.05 & 0.04 & 0.00 & 0.00 \\
TabPFN & 1 & 14 & 6.67 & 7 & 0.02 & 0.02 & 0.05 & 0.04 & 0.00 & 0.00 \\
XGBoost (default) & 1 & 28 & 7.94 & 6 & 0.07 & 0.03 & 0.03 & 0.03 & 1.86 & 0.45 \\
CatBoost (default) & 1 & 33 & 9.82 & 7 & 0.11 & 0.05 & 0.03 & 0.02 & 31.31 & 0.97 \\
ResNet & 1 & 25 & 11.15 & 10 & 0.10 & 0.06 & 0.04 & 0.04 & 8.59 & 5.38 \\
SAINT & 1 & 32 & 11.77 & 8.5 & 0.08 & 0.04 & 0.04 & 0.03 & 127.95 & 89.42 \\
LightGBM & 1 & 34 & 12.33 & 11 & 0.06 & 0.03 & 0.08 & 0.04 & 1.31 & 0.40 \\
LightGBM (default) & 1 & 37 & 13.83 & 13 & 0.08 & 0.05 & 0.05 & 0.05 & 1.55 & 0.66 \\
FTTransformer & 2 & 29 & 14.70 & 13 & 0.11 & 0.06 & 0.04 & 0.03 & 18.28 & 13.55 \\
DANet & 2 & 34 & 14.81 & 14.5 & 0.06 & 0.06 & 0.05 & 0.04 & 59.75 & 53.07 \\
SAINT (default) & 2 & 39 & 15.19 & 12 & 0.08 & 0.04 & 0.04 & 0.04 & 104.13 & 64.77 \\
ResNet (default) & 2 & 41 & 16.70 & 14 & 0.14 & 0.06 & 0.06 & 0.04 & 7.59 & 5.04 \\
RandomForest & 3 & 39 & 17.42 & 15 & 0.15 & 0.10 & 0.08 & 0.03 & 0.36 & 0.25 \\
MLP-rtdl & 4 & 39 & 17.44 & 14.5 & 0.18 & 0.10 & 0.06 & 0.04 & 6.55 & 4.82 \\
SVM & 1 & 35 & 18.21 & 18.5 & 0.11 & 0.07 & 0.04 & 0.03 & 20.41 & 2.83 \\
STG & 1 & 40 & 18.63 & 18.5 & 0.14 & 0.07 & 0.03 & 0.03 & 16.03 & 15.40 \\
DeepFM & 1 & 38 & 18.75 & 18.5 & 0.20 & 0.10 & 0.09 & 0.08 & 6.59 & 5.13 \\
TabTransformer & 1 & 37 & 19.32 & 19 & 0.15 & 0.09 & 0.05 & 0.04 & 13.81 & 9.59 \\
RandomForest (default) & 3 & 34 & 19.55 & 20 & 0.24 & 0.12 & 0.03 & 0.02 & 0.34 & 0.28 \\
TabFlex (default) & 5 & 37 & 20.32 & 22 & 0.24 & 0.11 & 0.04 & 0.02 & 1.18 & 0.47 \\
TabFlex & 5 & 37 & 20.32 & 22 & 0.24 & 0.11 & 0.04 & 0.02 & 1.18 & 0.47 \\
FTTransformer (default) & 4 & 38 & 20.44 & 20 & 0.19 & 0.07 & 0.06 & 0.05 & 16.44 & 11.91 \\
TabNet & 1 & 43 & 20.84 & 18.5 & 0.15 & 0.12 & 0.09 & 0.06 & 27.02 & 27.10 \\
MLP & 5 & 37 & 21.06 & 22 & 0.21 & 0.13 & 0.06 & 0.04 & 9.23 & 5.19 \\
MLP-rtdl (default) & 1 & 41 & 21.62 & 21.5 & 0.30 & 0.14 & 0.12 & 0.06 & 6.02 & 4.31 \\
NODE & 10 & 36 & 21.64 & 21.5 & 0.20 & 0.13 & 0.04 & 0.02 & 163.01 & 133.36 \\
DeepFM (default) & 2 & 42 & 21.95 & 21 & 0.25 & 0.15 & 0.11 & 0.09 & 6.63 & 5.11 \\
DANet (default) & 6 & 41 & 22.12 & 21.5 & 0.12 & 0.09 & 0.08 & 0.05 & 40.91 & 39.91 \\
LinearModel & 8 & 39 & 22.31 & 20.5 & 0.27 & 0.13 & 0.04 & 0.03 & 0.04 & 0.02 \\
NODE (default) & 8 & 38 & 23.32 & 25.5 & 0.22 & 0.16 & 0.03 & 0.02 & 54.55 & 42.98 \\
SVM (default) & 2 & 41 & 23.52 & 23 & 0.14 & 0.08 & 0.04 & 0.02 & 4.32 & 0.83 \\
TabTransformer (default) & 3 & 41 & 24.24 & 25 & 0.22 & 0.11 & 0.06 & 0.04 & 14.72 & 11.31 \\
TabNet (default) & 2 & 44 & 25.73 & 27 & 0.23 & 0.16 & 0.12 & 0.07 & 24.20 & 23.63 \\
MLP (default) & 6 & 40 & 25.79 & 27.5 & 0.36 & 0.19 & 0.10 & 0.07 & 8.47 & 5.43 \\
VIME & 4 & 39 & 26.23 & 28 & 0.23 & 0.17 & 0.04 & 0.03 & 21.16 & 15.32 \\
STG (default) & 9 & 41 & 27.40 & 28 & 0.24 & 0.14 & 0.03 & 0.02 & 13.76 & 13.23 \\
DecisionTree & 10 & 40 & 28.00 & 30 & 0.30 & 0.23 & 0.14 & 0.08 & 0.12 & 0.01 \\
KNN & 7 & 43 & 30.35 & 32 & 0.29 & 0.26 & 0.13 & 0.09 & 0.03 & 0.00 \\
NAM & 7 & 42 & 31.27 & 34 & 0.27 & 0.11 & 0.03 & 0.02 & 91.67 & 62.74 \\
VIME (default) & 18 & 42 & 33.30 & 35.5 & 0.38 & 0.28 & 0.09 & 0.02 & 20.39 & 12.83 \\
DecisionTree (default) & 13 & 45 & 33.64 & 36 & 0.62 & 0.68 & 0.31 & 0.17 & 0.12 & 0.02 \\
KNN (default) & 7 & 44 & 35.35 & 37 & 0.56 & 0.54 & 0.22 & 0.17 & 0.03 & 0.00 \\
NAM (default) & 32 & 44 & 40.00 & 41 & 0.50 & 0.53 & 0.17 & 0.07 & 43.86 & 35.75 \\
\bottomrule
\end{tabular}
